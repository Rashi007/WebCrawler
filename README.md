# WebCrawler
Downloads web pages and print all URL's on that page
Works in a similar pattern as the Google spider crawl works ;)
Searches for URL's by using regular expression.
Instead of looking for hyperlinks, we just look for patterns of the form: http:// followed by an alternating sequence of alphanumeric characters and dots, ending with a sequence of alphanumeric characters.
